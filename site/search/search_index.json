{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"The Model Database The Model Database <p>Organizing the world's models \u2014 one idea at a time.</p> <p>Coming soon. Stay curious.</p> <p>\u00a9 2025 themodeldatabase.com</p>"},{"location":"AI/","title":"Artificial Intelligence (AI)","text":"<p>Artificial Intelligence (AI) is the broad field of building machines that can perform tasks requiring intelligence.</p>"},{"location":"AI/#subdirectories","title":"Subdirectories","text":"<ul> <li>Machine Learning</li> </ul>"},{"location":"AI/ML/","title":"Machine Learning (ML)","text":"<p>Machine Learning (ML) is a subset of AI focused on building systems that learn patterns from data.</p>"},{"location":"AI/ML/#subdirectories","title":"Subdirectories","text":"<ul> <li>Computer Vision</li> </ul>"},{"location":"AI/ML/CV/","title":"Computer Vision (CV)","text":"<p>Computer Vision (CV) is the field of Machine Learning focused on enabling machines to interpret and understand visual data such as images and videos.</p>"},{"location":"AI/ML/CV/#topics-covered-here","title":"Topics Covered Here","text":"<ul> <li>Segmentation \u2013 Dividing an image into meaningful parts.</li> <li>Object Detection \u2013 Locating and classifying objects in images.</li> <li>Vision Foundation Models \u2013 Large, general-purpose models trained on massive datasets.</li> </ul>"},{"location":"AI/ML/CV/#subdirectories","title":"Subdirectories","text":"<ul> <li>Vision Foundation Models</li> </ul>"},{"location":"AI/ML/CV/Vision-Foundation-Models/","title":"Vision Foundation Models","text":"<p>Vision Foundation Models (VFMs) are large, general-purpose computer vision models trained on massive datasets, often without labels. They provide reusable features for many tasks like segmentation, depth estimation, or retrieval.</p>"},{"location":"AI/ML/CV/Vision-Foundation-Models/#notes","title":"Notes","text":"<ul> <li>DINOv3</li> </ul>"},{"location":"AI/ML/CV/Vision-Foundation-Models/#future-topics","title":"Future Topics","text":"<ul> <li>SAM (Segment Anything Model)</li> <li>CLIP</li> <li>Others...</li> </ul>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/","title":"DINOv3","text":""},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#metas-dinov3-a-new-era-for-vision-ai","title":"Meta\u2019s DINOv3 \u2014 A New Era for Vision AI","text":"<p>Meta\u2019s DINOv3 is the latest leap in self-supervised computer vision\u2014a foundation model designed to understand images at a highly detailed, pixel-level without needing any labeled training data. It\u2019s trained on over 1.7 billion unlabeled images and scales up to 7 billion parameters, delivering rich, general-purpose features for almost any visual task.</p>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#what-makes-dinov3-special","title":"What Makes DINOv3 Special","text":""},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#1-gram-anchoring","title":"1. Gram Anchoring","text":"<p>A novel loss function that ensures dense patch-level features remain consistent throughout long training sessions, avoiding feature collapse and maintaining quality.</p>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#2-ultra-high-resolution-support","title":"2. Ultra-High-Resolution Support","text":"<p>After training, DINOv3 is tuned to handle resolutions from 512 px up to 4K, making it ideal for tasks that need fine detail, like satellite imagery or medical scans.</p>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#3-versatility-without-fine-tuning","title":"3. Versatility Without Fine-Tuning","text":"<p>The model\u2019s \u201cfrozen backbone\u201d works as-is\u2014you can run segmentation, depth estimation, object tracking, or image retrieval without retraining.</p>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#4-scalable-model-sizes","title":"4. Scalable Model Sizes","text":"<p>While the flagship model is huge, Meta also provides distilled versions (ViT-S, ViT-B, ViT-L, ViT-H+) that are smaller, faster, and more deployment-friendly.</p>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#5-optional-text-alignment","title":"5. Optional Text Alignment","text":"<p>When paired with a text encoder, DINOv3 can perform zero-shot classification and cross-modal retrieval, similar to CLIP, without retraining the vision backbone.</p>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#what-dinov3-can-do","title":"What DINOv3 Can Do","text":"<p>DINOv3 is built as a dense vision powerhouse, enabling a wide range of computer vision tasks:</p>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#dense-prediction-pixel-level-understanding","title":"Dense Prediction (Pixel-Level Understanding)","text":"<ul> <li> <p>Semantic segmentation \u2013 Assign a category to every pixel (road, tree, building, sky).</p> </li> <li> <p>Instance segmentation \u2013 Separate individual objects within a scene.</p> </li> <li> <p>Panoptic segmentation \u2013 Combine semantic and instance segmentation.</p> </li> </ul>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#geometric-3d-understanding","title":"Geometric &amp; 3D Understanding","text":"<ul> <li> <p>Monocular depth estimation \u2013 Predict depth from a single image.</p> </li> <li> <p>Surface normal estimation \u2013 Understand the 3D structure of surfaces.</p> </li> <li> <p>3D correspondence matching \u2013 Track the same point across different images.</p> </li> </ul>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#matching-retrieval","title":"Matching &amp; Retrieval","text":"<ul> <li> <p>Object tracking in video \u2013 Follow moving subjects frame-by-frame.</p> </li> <li> <p>Feature matching \u2013 Align corresponding patches across views.</p> </li> <li> <p>Image retrieval \u2013 Search for visually similar images in large datasets.</p> </li> </ul>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#high-resolution-applications","title":"High-Resolution Applications","text":"<ul> <li>Works at up to 4K resolution without losing feature quality\u2014critical for medical imaging, remote sensing, and industrial inspection.</li> </ul>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#domain-adaptation-without-labels","title":"Domain Adaptation Without Labels","text":"<ul> <li>Excels in specialized domains (microscopy, satellite, manufacturing) where labeled datasets are scarce or unavailable.</li> </ul>"},{"location":"AI/ML/CV/Vision-Foundation-Models/DINOv3/#why-it-matters","title":"Why It Matters","text":"<p>DINOv3 eliminates the bottleneck of labeled data, enabling AI to learn directly from raw visual information. This makes it a flexible and powerful backbone for:</p> <ul> <li> <p>Research in new domains</p> </li> <li> <p>Real-world industrial deployments</p> </li> <li> <p>Cross-modal AI applications with text and images</p> </li> </ul> <p>With Meta open-sourcing the model under a permissive license, DINOv3 brings cutting-edge vision AI within reach for both researchers and industry innovators.</p> <p>Made with ChatGPT</p>"},{"location":"python/","title":"\ud83d\udc0d Python Package Index","text":"<p>My manually curated list of Python packages.</p>"},{"location":"python/#packages","title":"\ud83d\udce6 Packages","text":"<ul> <li>requests \u2013 Python HTTP for Humans.</li> <li>numpy \u2013 Fundamental package for array computing in Python</li> <li>fastapi \u2013 FastAPI framework, high performance, easy to learn, fast to code, ready for production</li> </ul>"},{"location":"python/fastapi/","title":"fastapi","text":"<p>FastAPI framework, high performance, easy to learn, fast to code, ready for production</p>","tags":["web","framework","async"]},{"location":"python/fastapi/#install","title":"\ud83d\udce6 Install","text":"<pre><code>pip install fastapi==0.116.1\n</code></pre>","tags":["web","framework","async"]},{"location":"python/fastapi/#links","title":"\ud83d\udd17 Links","text":"<ul> <li>PyPI Project Page</li> <li>Project Homepage</li> </ul>","tags":["web","framework","async"]},{"location":"python/numpy/","title":"numpy","text":"<p>Fundamental package for array computing in Python</p>","tags":["math","ml","core"]},{"location":"python/numpy/#install","title":"\ud83d\udce6 Install","text":"<pre><code>pip install numpy==2.3.2\n</code></pre>","tags":["math","ml","core"]},{"location":"python/numpy/#links","title":"\ud83d\udd17 Links","text":"<ul> <li>PyPI Project Page</li> <li>Project Homepage</li> </ul>","tags":["math","ml","core"]},{"location":"python/requests/","title":"requests","text":"<p>Python HTTP for Humans.</p>","tags":["http client","utilities"]},{"location":"python/requests/#install","title":"\ud83d\udce6 Install","text":"<pre><code>pip install requests==2.32.4\n</code></pre>","tags":["http client","utilities"]},{"location":"python/requests/#links","title":"\ud83d\udd17 Links","text":"<ul> <li>PyPI Project Page</li> <li>Project Homepage</li> </ul>","tags":["http client","utilities"]}]}